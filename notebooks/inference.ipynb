{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import torchvision.transforms as tvt\n",
    "\n",
    "from config_manager.manager import Params\n",
    "from model.cascade_net import CascadeNet\n",
    "from utils.utils import read_json\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"../output/experiment\"\n",
    "\n",
    "NUM_CASCADES = 1\n",
    "\n",
    "param_dict = {\n",
    "    \"data_path\": \"../output/caesar\",#\"../output/dataset_20230207-134027\",\n",
    "    \"save_path\": SAVE_PATH,\n",
    "    \"tb_path\": os.path.join(SAVE_PATH, \"pcd\"),\n",
    "    \"height\": 720,\n",
    "    \"width\": 1280,\n",
    "    \"resize\": 224,\n",
    "    \"scale\": 2.0,\n",
    "    \"num_encodings\": 6,\n",
    "    \"out_channels\": [1 for _ in range(NUM_CASCADES)],\n",
    "    \"filters\": [[64, 128, 256, 512, 512, 512, 512] for _ in range(NUM_CASCADES)],\n",
    "    \"kernels\": [[3, 3, 3, 3, 3, 3, 3] for _ in range(NUM_CASCADES)],\n",
    "    \"style_nodes\": [f\"net_stack.{NUM_CASCADES - 1}.encoder.{i + 1}.activation\" for i in range(3)],\n",
    "    \"cascade_layers\": [f\"net_stack.{i}.out_conv.activation\" for i in range(NUM_CASCADES - 1)],\n",
    "    \"output_layer\": f\"net_stack.{NUM_CASCADES - 1}.out_conv.activation\",\n",
    "}\n",
    "\n",
    "params = Params(param_dict)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = np.random.randint(0, 320)\n",
    "idx = np.random.randint(0, 4308)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = glob.glob(params.data_path + \"/**/*.png\", recursive=True)\n",
    "bim = img_list[idx]\n",
    "#fim = img_list[idx + 320]\n",
    "fim = img_list[idx + 4308]\n",
    "print(bim)\n",
    "print(fim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_path: str, params: Params) -> Tuple[np.ndarray, torch.Tensor]:\n",
    "    \"\"\"Load image and transform to get a tensor for inference\"\"\"\n",
    "    img = np.asarray(Image.open(img_path))\n",
    "    img_tensor = torch.tensor(img, dtype=torch.float32)\n",
    "\n",
    "    mask = img_tensor > 0.0\n",
    "    min_ = img_tensor[mask].min()\n",
    "    max_ = img_tensor.max()\n",
    "    img_tensor[mask] = ((img_tensor[mask] - min_) / (max_ - min_))\n",
    "    result = img_tensor.unsqueeze(0)\n",
    "\n",
    "    result = tvt.functional.affine(result, shear=0.0, scale=params.scale, translate=(0, 0), angle=0.0)\n",
    "    rsz = tvt.Resize((params.resize, params.resize), interpolation=tvt.InterpolationMode.NEAREST)\n",
    "    result = rsz(result)\n",
    "\n",
    "    return img, result.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np, img_tensor = load_img(fim, params)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_np.max())\n",
    "print(img_np.min())\n",
    "print(img_np.dtype)\n",
    "print()\n",
    "print(img_tensor.max())\n",
    "print(img_tensor.min())\n",
    "print(img_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_np, cmap=\"gray\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(img_np, bins=50)\n",
    "plt.stairs(counts, bins, fill=True)\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tensor.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(img_tensor.squeeze().numpy(), bins=50)\n",
    "plt.stairs(counts, bins, fill=True)\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = CascadeNet(params)\n",
    "NODES = params.style_nodes + params.cascade_layers + [params.output_layer]\n",
    "net = create_feature_extractor(base_model, return_nodes=NODES)\n",
    "net.load_state_dict(\n",
    "    torch.load(os.path.join(params.save_path, \"best_net_c.pt\"), map_location=torch.device('cpu'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, back_img_tensor = load_img(bim, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(back_img_tensor.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (img_tensor > 0.0).to(torch.float32)\n",
    "#mask = (back_img_tensor > 0.0).to(torch.float32)\n",
    "\n",
    "plt.imshow(mask.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    pred = net(img_tensor, mask)\n",
    "out = pred[params.output_layer]\n",
    "print(out.max())\n",
    "print(out.min())\n",
    "print(out.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(out.squeeze().numpy(), bins=50)\n",
    "plt.stairs(counts, bins, fill=True)\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_prediction(img: torch.Tensor, img_np: np.ndarray, params: Params) -> np.ndarray:\n",
    "    \"\"\"Unnormalize prediction to get original scale\"\"\"\n",
    "    rsz = tvt.Resize((params.height, params.width), interpolation=tvt.InterpolationMode.NEAREST)\n",
    "    result = rsz(img)\n",
    "    result = tvt.functional.affine(\n",
    "        result, shear=0.0, scale=1/params.scale, translate=(0, 0), angle=0.0\n",
    "    )\n",
    "\n",
    "    mask = img_np > 0.0\n",
    "    min_ = img_np[mask].min()\n",
    "    max_ = img_np.max()\n",
    "\n",
    "    result = result.squeeze()\n",
    "\n",
    "    result[mask] = (result[mask] * (max_ - min_)) + min_\n",
    "\n",
    "    return result.numpy().astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = unnormalize_prediction(out, img_np, params)\n",
    "print(res.max())\n",
    "print(res.min())\n",
    "print(res.dtype)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res, cmap=\"gray\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(res, bins=50)\n",
    "plt.stairs(counts, bins, fill=True)\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = glob.glob(params.data_path + \"/**/*.json\", recursive=True)\n",
    "\n",
    "intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
    "    **read_json(list(filter(lambda x: \"intrinsic\" in x, json_files))[0])\n",
    ")\n",
    "extrinsic = read_json(list(filter(lambda x: \"extrinsic\" in x, json_files))[0])[\"extrinsics\"]\n",
    "scale = read_json(list(filter(lambda x: \"scale\" in x, json_files))[0])[\"depth_scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud.create_from_depth_image(\n",
    "    o3d.geometry.Image(res),\n",
    "    intrinsic,\n",
    "    extrinsic,\n",
    "    depth_scale=scale,\n",
    "    depth_trunc=4000.0\n",
    ")\n",
    "\n",
    "front_pcd = o3d.geometry.PointCloud.create_from_depth_image(\n",
    "    o3d.geometry.Image(img_np.astype(\"uint16\")),\n",
    "    intrinsic,\n",
    "    extrinsic,\n",
    "    depth_scale=scale,\n",
    "    depth_trunc=4000.0\n",
    ")\n",
    "\n",
    "back_orig_img = np.asarray(Image.open(bim))\n",
    "back_pcd = o3d.geometry.PointCloud.create_from_depth_image(\n",
    "    o3d.geometry.Image(back_orig_img.astype(\"uint16\")),\n",
    "    intrinsic,\n",
    "    extrinsic,\n",
    "    depth_scale=scale,\n",
    "    depth_trunc=4000.0\n",
    ")\n",
    "\n",
    "_, ind = pcd.remove_statistical_outlier(nb_neighbors=50, std_ratio=1.0)\n",
    "#_, ind = pcd.remove_radius_outlier(nb_points=35, radius=20.0)\n",
    "inlier_cloud = pcd.select_by_index(ind)\n",
    "\n",
    "#o3d.visualization.draw_geometries([inlier_cloud])\n",
    "#o3d.visualization.draw_geometries([inlier_cloud, front_pcd])\n",
    "o3d.visualization.draw_geometries([back_pcd, inlier_cloud.translate((0, 650, 0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from open3d.visualization.tensorboard_plugin import summary\n",
    "# from open3d.visualization.tensorboard_plugin.util import to_dict_batch\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = SummaryWriter(params.tb_path)\n",
    "# writer.add_3d(\"pcd\", to_dict_batch([pcd]), step=0)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TENSORBOARD_BINARY\"] = \"/opt/conda/envs/cv3d-env/bin/tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir ../output/experiment/pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "cv3d-env",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cv3d-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2f71e6011faa0109c6544a926ac70c80d3ea1a0e18aed42a92f791a760d489a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
